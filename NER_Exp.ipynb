{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ry9Pa7dq_dZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmAVeucbrcMz"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE8VEjpnrc8C"
      },
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").ffill()\n",
        "words = list(data[\"Word\"].unique())\n",
        "tags = list(data[\"Tag\"].unique())\n",
        "\n",
        "if \"ENDPAD\" not in words:\n",
        "    words.append(\"ENDPAD\")\n",
        "\n",
        "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DGpH3WzrmDi"
      },
      "outputs": [],
      "source": [
        "data.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-xy1yJtIUdj"
      },
      "source": [
        "Essential info about tagged entities:\n",
        "```\n",
        "geo = Geographical Entity\n",
        "org = Organization\n",
        "per = Person\n",
        "gpe = Geopolitical Entity\n",
        "tim = Time indicator\n",
        "art = Artifact\n",
        "eve = Event\n",
        "nat = Natural Phenomenon\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOWkBoLXsPvD"
      },
      "outputs": [],
      "source": [
        "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
        "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6_c7uwHsa_q"
      },
      "outputs": [],
      "source": [
        "print(\"Unique tags are:\", tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zo6uyoCsiEb"
      },
      "outputs": [],
      "source": [
        "# Group words by sentences\n",
        "class SentenceGetter:\n",
        "    def __init__(self, data):\n",
        "        self.grouped = data.groupby(\"Sentence #\", group_keys=False).apply(\n",
        "            lambda s: [(w, t) for w, t in zip(s[\"Word\"], s[\"Tag\"])]\n",
        "        )\n",
        "        self.sentences = list(self.grouped)\n",
        "\n",
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-pZFuuAs4Xa"
      },
      "outputs": [],
      "source": [
        "sentences[35]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Yd8hqMssdK"
      },
      "outputs": [],
      "source": [
        "# Encode sentences\n",
        "X = [[word2idx[w] for w, t in s] for s in sentences]\n",
        "y = [[tag2idx[t] for w, t in s] for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ipTK2DOstD3j"
      },
      "outputs": [],
      "source": [
        "word2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eWV-M4IftKUy"
      },
      "outputs": [],
      "source": [
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6hFevHstXKL"
      },
      "outputs": [],
      "source": [
        "# Pad sequences\n",
        "max_len = 50\n",
        "X_pad = pad_sequence([torch.tensor(seq) for seq in X], batch_first=True, padding_value=word2idx[\"ENDPAD\"])\n",
        "y_pad = pad_sequence([torch.tensor(seq) for seq in y], batch_first=True, padding_value=tag2idx[\"O\"])\n",
        "X_pad = X_pad[:, :max_len]\n",
        "y_pad = y_pad[:, :max_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TA2On7iAtzAK"
      },
      "outputs": [],
      "source": [
        "X_pad[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Cx7lJhft4aa"
      },
      "outputs": [],
      "source": [
        "y_pad[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74HBxw81tap6"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukXTrKSPtipK"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.X[idx],\n",
        "            \"labels\": self.y[idx]\n",
        "        }\n",
        "\n",
        "train_loader = DataLoader(NERDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(NERDataset(X_test, y_test), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFu8201Qtnl6"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "class BiLSTMTagger(nn.Module):\n",
        "    # Include your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # Include your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onjJJSuAuFyL"
      },
      "outputs": [],
      "source": [
        "model =\n",
        "loss_fn =\n",
        "optimizer ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlcDlPEruRB6"
      },
      "outputs": [],
      "source": [
        "# Training and Evaluation Functions\n",
        "def train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3):\n",
        "    # Include the training and evaluation functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rALxE4gTuVUr"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, X_test, y_test):\n",
        "    model.eval()\n",
        "    true_tags, pred_tags = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(input_ids)\n",
        "            preds = torch.argmax(outputs, dim=-1)\n",
        "            for i in range(len(labels)):\n",
        "                for j in range(len(labels[i])):\n",
        "                    if labels[i][j] != tag2idx[\"O\"]:\n",
        "                        true_tags.append(idx2tag[labels[i][j].item()])\n",
        "                        pred_tags.append(idx2tag[preds[i][j].item()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVJ5f5hyubC0"
      },
      "outputs": [],
      "source": [
        "# Run training and evaluation\n",
        "train_losses, val_losses = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3)\n",
        "evaluate_model(model, test_loader, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HpgHVLhwPWE"
      },
      "outputs": [],
      "source": [
        "# Plot loss\n",
        "print('Name: ')\n",
        "print('Register Number:')\n",
        "history_df = pd.DataFrame({\"loss\": train_losses, \"val_loss\": val_losses})\n",
        "history_df.plot(title=\"Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7YGTaIPwQEY"
      },
      "outputs": [],
      "source": [
        "# Inference and prediction\n",
        "i = 125\n",
        "model.eval()\n",
        "sample = X_test[i].unsqueeze(0).to(device)\n",
        "output = model(sample)\n",
        "preds = torch.argmax(output, dim=-1).squeeze().cpu().numpy()\n",
        "true = y_test[i].numpy()\n",
        "\n",
        "print('Name:')\n",
        "print('Register Number:')\n",
        "print(\"{:<15} {:<10} {}\\n{}\".format(\"Word\", \"True\", \"Pred\", \"-\" * 40))\n",
        "for w_id, true_tag, pred_tag in zip(X_test[i], y_test[i], preds):\n",
        "    if w_id.item() != word2idx[\"ENDPAD\"]:\n",
        "        word = words[w_id.item() - 1]\n",
        "        true_label = tags[true_tag.item()]\n",
        "        pred_label = tags[pred_tag]\n",
        "        print(f\"{word:<15} {true_label:<10} {pred_label}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
